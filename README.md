# ğŸ“Š Traballho_EAD_ACD - Monitoramento Automatizado de TendÃªncias em InteligÃªncia Artificial para Desenvolvedores (Devs)

**Desenvolvedores:**  
Artur Aiello, Carolina Navarro, Denis Pereira

Este repositÃ³rio foi criado para documentar o trabalho desenvolvido pelos discentes Artur Aiello, Carolina Navarro e Denis Pereira, no Ã¢mbito da disciplina ExtraÃ§Ã£o AutomÃ¡tica de Dados, ministrada pelo professor OtÃ¡vio Xavier, da Universidade Federal de GoiÃ¡s.

---

## âœ¨ DescriÃ§Ã£o do Projeto

Este projeto consiste em um sistema automatizado de web scraping (raspagem de dados da web) para coletar notÃ­cias e artigos sobre tendÃªncias em InteligÃªncia Artificial Desenvolvedores (Devs). A proposta Ã© manter um monitor de tendÃªncias em IA voltadas Ã  Devs, agregando conteÃºdos de fontes pÃºblicas de tecnologia como TecMundo, Canaltech, The Verge, entre outras. Assim, profissionais e interessados podem acompanhar inovaÃ§Ãµes e aplicaÃ§Ãµes de IA no campo, sem precisar buscar manualmente em mÃºltiplos sites. 

A soluÃ§Ã£o realiza a busca de novos conteÃºdos de forma automatizada a cada semana. Para isso, utiliza Playwright â€“ uma ferramenta moderna de automaÃ§Ã£o de navegador criada pela Microsoft que controla navegadores como Chrome, Firefox e WebKit, permitindo carregar pÃ¡ginas com conteÃºdo dinÃ¢mico (Javascript) como se fosse um usuÃ¡rio real. Em seguida, as pÃ¡ginas sÃ£o interpretadas com a biblioteca BeautifulSoup (Python) para extrair os dados relevantes de maneira simplificada, sem a necessidade de lidar diretamente com HTML bruto ou expressÃµes regulares. Os dados coletados passam por uma etapa de limpeza e entÃ£o sÃ£o analisados para identificar tÃ³picos em destaque, frequÃªncia de termos e outras tendÃªncias de IA no contexto de SST. Finalmente, um aplicativo web criado com Streamlit apresenta os resultados em um dashboard interativo, com grÃ¡ficos e listas de notÃ­cias filtradas. O Streamlit Ã© um framework Python de cÃ³digo aberto que permite construir aplicativos de dados dinÃ¢micos com poucas linhas de cÃ³digo, ideal para disponibilizar visualizaÃ§Ãµes de forma fÃ¡cil e acessÃ­vel diretamente no navegador. 

Em resumo, o sistema cobre todo o fluxo desde a coleta de informaÃ§Ãµes atualizadas sobre IA em SST, passando pelo processamento e anÃ¡lise dos dados, atÃ© a visualizaÃ§Ã£o dos insights em um dashboard amigÃ¡vel. Tudo isso Ã© feito com foco em ser simples de usar, mesmo para quem tem pouca experiÃªncia em programaÃ§Ã£o, bastando seguir as instruÃ§Ãµes de instalaÃ§Ã£o e execuÃ§Ã£o abaixo.

---

## ğŸ“¦ Funcionalidades Principais

- **Coleta automÃ¡tica** de notÃ­cias e lanÃ§amentos de ferramentas de IA de mÃºltiplos sites (Anthropic, TecMundo, Canaltech, The Verge, Gizmodo, AI Directory, etc.).
- **Estrutura de dados organizada** (raw/clean) para facilitar manipulaÃ§Ã£o e atualizaÃ§Ã£o.
- **Filtro semÃ¢ntico inteligente**: prioriza notÃ­cias realmente relevantes para Devs/IA usando IA de linguagem.
- **Dashboard interativo** (Streamlit): busca por tema, filtro por fonte, ranking de ferramentas, exportaÃ§Ã£o para Excel.
- **CÃ³digo modular, comentado e fÃ¡cil de adaptar.**

---

## ğŸ› ï¸ Tecnologias e DependÃªncias

- **Python 3.10+**
- [BeautifulSoup4](https://www.crummy.com/software/BeautifulSoup/) â€” parsing HTML
- [Playwright](https://playwright.dev/python/) â€” scraping de pÃ¡ginas dinÃ¢micas (JS)
- [pandas](https://pandas.pydata.org/) â€” manipulaÃ§Ã£o de dados
- [streamlit](https://streamlit.io/) â€” dashboard interativo
- [sentence-transformers](https://www.sbert.net/) â€” filtro semÃ¢ntico IA
- [openpyxl](https://openpyxl.readthedocs.io/) â€” exportaÃ§Ã£o Excel

---

### InstalaÃ§Ã£o das dependÃªncias

```bash
# Crie e ative o ambiente virtual
python3 -m venv .venv
source .venv/bin/activate    # (Linux/Mac)
# .venv\Scripts\activate     # (Windows)

# Instale as bibliotecas principais
pip install beautifulsoup4 playwright pandas streamlit sentence-transformers openpyxl

# Instale navegadores Playwright (apenas 1 vez!)
playwright install
```
---

### Estrutura das Pastas

```
â”œâ”€â”€ scrape.py                  # Script principal de coleta de notÃ­cias/ferramentas
â”œâ”€â”€ app.py                     # Dashboard interativo em Streamlit
â”œâ”€â”€ clean_data/                # Dados limpos prontos para anÃ¡lise
â”‚    â””â”€â”€ noticias_YYYY-MM-DD.json
â”œâ”€â”€ raw_data/                  # (opcional) Dados brutos, se quiser guardar o HTML original
â”œâ”€â”€ notebooks/                 # (opcional) Notebooks de anÃ¡lise/experimentos
â”œâ”€â”€ docs/                      # DocumentaÃ§Ã£o extra, prints, diagramas
â”œâ”€â”€ requirements.txt           # (opcional) Lista das dependÃªncias do projeto
â””â”€â”€ README.md
```
---

### Diagrama Resumido do Pipeline
```
+------------------+
|   MÃºltiplas      |
|     Fontes       | <--- Anthropic, TecMundo, Canaltech, The Verge, etc.
+------------------+
          |
          v
+---------------------+
|   scrape.py         |  # Coleta automatizada (BeautifulSoup/Playwright)
+---------------------+
          |
          v
+---------------------+
|  Limpeza e Filtros  |  # Duplicatas, campos obrigatÃ³rios
+---------------------+
          |
          v
+------------------------------+
| clean_data/noticias_YYYY-MM-DD.json |
+------------------------------+
          |
          v
+----------------------+
|    app.py (Streamlit)|
+----------------------+
          |
          v
+----------------------+
| Dashboard Interativo |
+----------------------+
       |        |
       |        +--> ExportaÃ§Ã£o para Excel (.xlsx)
       +--> Busca semÃ¢ntica, filtros, ranking, agrupamento
```
---

### ğŸš€ Como Executar o Pipeline Completo
Clone este repositÃ³rio

```bash
git clone <[url-do-repo](https://github.com/ArturAiello-Dev/Traballho_EAD_ACD.git)>
cd <Traballho_EAD_ACD>
(Opcional) Crie e ative um ambiente virtual
```

```bash
python3 -m venv .venv
source .venv/bin/activate      # Linux/Mac
# .venv\Scripts\activate       # Windows
Instale as dependÃªncias
```

```bash
pip install -r requirements.txt
# ou manualmente conforme seÃ§Ã£o anterior
playwright install    # NecessÃ¡rio para scraping de sites dinÃ¢micos!
Execute a coleta de dados
```

```bash
python scrape.py
Isso irÃ¡ gerar um arquivo JSON em clean_data/ com as notÃ­cias/ferramentas mais recentes.
```

Inicie o dashboard

```bash
streamlit run app.py
O dashboard abrirÃ¡ automaticamente no navegador.
```

### ğŸ§© ConfiguraÃ§Ã£o e PersonalizaÃ§Ã£o
Adicione/remova fontes: edite scrape.py para incluir novos sites/blogs relevantes.

Ajuste filtros semÃ¢nticos: modifique os parÃ¢metros em app.py para calibrar o nÃ­vel de relevÃ¢ncia.

Troque temas visuais: customize o banner, cores e layout direto no Streamlit.

### ğŸ‘©â€ğŸ’» ExecuÃ§Ã£o Recorrente
Para atualizar as notÃ­cias semanalmente, execute novamente o scrape.py antes de abrir o dashboard, ou agende uma execuÃ§Ã£o automÃ¡tica com cron (Linux) ou Agendador de Tarefas (Windows).

### â“ ResoluÃ§Ã£o de Problemas
1) Nenhum dado aparece no dashboard?

Verifique se o arquivo JSON estÃ¡ sendo criado em clean_data/.
Rode python scrape.py e confira as mensagens no terminal (pode haver bloqueios, mudanÃ§as de layout dos sites, problemas de conexÃ£o).
Veja se as dependÃªncias estÃ£o corretamente instaladas (pip install ...).

2) Erro ao exportar para Excel?

Instale o pacote: pip install openpyxl

3) Sites sem resultados?

Alguns sites mudam seu layout ou bloqueiam scraping; ajuste os seletores em scrape.py conforme necessÃ¡rio.

### ğŸ“„ LicenÃ§a e CrÃ©ditos
Todos os direitos das notÃ­cias e ferramentas pertencem a seus respectivos autores e sites.

O projeto respeita os termos de uso e polÃ­ticas das fontes (uso acadÃªmico, sem redistribuiÃ§Ã£o comercial dos dados coletados).

Desenvolvido por Artur Aiello, Carolina Navarro e Denis Pereira â€” 2025

### ğŸ“š ReferÃªncias
BeautifulSoup Documentation

Playwright Python

Streamlit Documentation

Sentence Transformers

---
